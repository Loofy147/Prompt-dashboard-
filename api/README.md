# Prompt Optimizer Module

## Executive Summary
The `prompt_optimizer` module is a core component of the Prompt Architect platform, transforming it from a passive analysis dashboard into an **active refinement engine**. By leveraging Large Language Models (LLMs), it automatically upgrades prompts across the six PES dimensions (Persona, Tone, Format, Specificity, Constraints, Context) to reach production-grade quality scores.

## Key Features
- **Meta-Optimization Pipeline**: Uses specialized prompts to improve specific quality dimensions identified as weak points.
- **Strategy-Based Budgets**:
  - `cost_efficient` (~$0.05): Minimal iterations for high-impact gains.
  - `balanced` (~$0.20): Optimal balance of cost and quality refinement.
  - `max_quality` (~$0.50): Exhaustive multi-pass optimization for critical prompts.
- **Multi-Iteration Refinement**: Implements a convergence-checked loop (up to 5 iterations) to ensure measurable improvement.
- **Cost Estimation**: Integrated pre-flight check that calculates estimated token usage and USD cost before execution.

## Architecture
The module acts as an orchestrator between three key systems:
1. **Quality Calculator**: Provides the target metrics and weights.
2. **Feature Analyzer**: Identifies the current strengths and weaknesses of the input prompt.
3. **LLM Generator**: Executes the refinement steps using high-performance models (Claude/GPT).

## Usage Guide

### Basic Optimization
```python
from prompt_optimizer import optimize_prompt

result = optimize_prompt(
    prompt="Write about AI.",
    target_quality=0.85,
    strategy="balanced"
)
print(f"Improved Q: {result.optimized_q}")
```

### Estimation-First
```python
from prompt_optimizer import estimate_optimization_cost

estimate = estimate_optimization_cost(
    prompt="Explain quantum computing.",
    target_q=0.90,
    strategy="max_quality"
)
print(f"Est. Cost: ${estimate.estimated_cost_usd}")
```

### Batch Optimization
Batch optimization is supported via the `/api/optimize/batch` endpoint, allowing for fleet-wide prompt upgrades.

## Configuration
Ensure the following environment variables are set:
- `ANTHROPIC_API_KEY`: Required for Claude-based optimization.
- `OPENAI_API_KEY`: Required for GPT-based optimization.

## Benchmarks
- **Latency**: <20s for `balanced` strategy.
- **Cost Accuracy**: >98% variance between estimate and actual.
- **Quality Gain**: Average Î”Q > +0.35 per session.

---
*Generated by Prompt Documentation Architect*
